{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from math import floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MIN_SIZE = 2\n",
    "MAX_SIZE = 10\n",
    "DEFAULT_SIZE = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to assert the builded grid is solvable\n",
    "def is_solvable(grid):\n",
    "    flat_grid = grid.flatten() \n",
    "    \n",
    "    inversions = 0\n",
    "    for i in range(len(flat_grid)):\n",
    "        for j in range(i + 1, len(flat_grid)):\n",
    "            if flat_grid[j] and flat_grid[i] and flat_grid[i] > flat_grid[j]:\n",
    "                inversions += 1\n",
    "    return inversions % 2 == 0\n",
    "\n",
    "def build_line(start_symb, stop_symb, sep_symb, line):\n",
    "    return '\\n%s%s%s\\n' % (start_symb, sep_symb.join(line), stop_symb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# State : Correspond a la grid\n",
    "# Actions: Dé deplacer :\n",
    "#0: dé en haut\n",
    "#1: dé a gauche\n",
    "#2: dé en bas\n",
    "#3: dé à droite\n",
    "\n",
    "class Grid :\n",
    "    def __init__(self,size=DEFAULT_SIZE) -> None:\n",
    "        assert size>=MIN_SIZE and size <= MAX_SIZE\n",
    "        self.size=size\n",
    "\n",
    "        while True:\n",
    "            grid=list(range(size**2))\n",
    "            random.shuffle(grid)\n",
    "            grid=np.asarray(grid).reshape(size, size)\n",
    "            if is_solvable(grid):break\n",
    "        self.state=grid\n",
    "\n",
    "\n",
    "    def take_action(self,action):\n",
    "      i, j = np.where(self.state == 0)\n",
    "      if len(i) > 0 and len(j) > 0:\n",
    "        i = i[0]\n",
    "        j = j[0]\n",
    "        if action == 0:\n",
    "            if i > 0:\n",
    "                self.state[i][j], self.state[i-1][j] = self.state[i-1][j], self.state[i][j]\n",
    "        elif action == 2:\n",
    "            if i < self.size-1:\n",
    "                self.state[i][j], self.state[i+1][j] = self.state[i+1][j], self.state[i][j]\n",
    "        elif action ==1:\n",
    "            if j > 0:\n",
    "                self.state[i][j], self.state[i][j-1] = self.state[i][j-1], self.state[i][j]\n",
    "        elif action == 3:\n",
    "            if j < self.size-1:\n",
    "                self.state[i][j], self.state[i][j+1] = self.state[i][j+1], self.state[i][j]\n",
    "\n",
    "    def is_finish(self):\n",
    "        ended_grid=[i for i in range(1,self.size**2)]\n",
    "        ended_grid.append(0)\n",
    "        return np.array_equal(\n",
    "            self.state,\n",
    "            np.asarray(ended_grid).reshape(self.size,self.size)\n",
    "            )\n",
    "    \n",
    "    def get_possible_actions(self)-> list[int]:\n",
    "        \"\"\"return the possible actions\"\"\"\n",
    "        actions=[i for i in range(0,4)]\n",
    "        pos_empty=self.get_empty_position()\n",
    "        if pos_empty[0]==0 : actions.remove(0)\n",
    "        elif pos_empty[0]==(self.size-1):actions.remove(2)\n",
    "        if pos_empty[1]==0:actions.remove(1)\n",
    "        elif pos_empty[1]==(self.size-1):actions.remove(3)\n",
    "        return  actions\n",
    "    \n",
    "    def get_empty_position(self)->tuple:\n",
    "        \"\"\"Return the position od the tuple\"\"\"\n",
    "        return floor(np.argmin(self.state)/self.size),np.argmin(self.state)%self.size\n",
    "\n",
    "    def get_good_place(self):\n",
    "      ended_grid=[i for i in range(1,self.size**2)]\n",
    "      ended_grid.append(0)\n",
    "      return (np.asarray(ended_grid).reshape(self.size,self.size) == self.state ).sum()\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        \"\"\"Renderer\"\"\"\n",
    "        tile_line = np.full(self.size, '─' * 4).tolist()\n",
    "        horizontal_line = build_line('├', '┤', '┼', tile_line)\n",
    "        first_horizontal_line = build_line('┌', '┐', '┬', tile_line)\n",
    "        last_horizontal_line = build_line('└', '┘', '┴', tile_line)\n",
    "        grid_to_show = first_horizontal_line\n",
    "        for count, row in enumerate(self.state):\n",
    "            grid_to_show += '│'\n",
    "            for tile in row:\n",
    "                if tile == 0:\n",
    "                    tile = '  '\n",
    "                grid_to_show += ' %s │' % '{0:>2}'.format(tile)\n",
    "            if not count == self.size - 1:\n",
    "                grid_to_show += horizontal_line\n",
    "        grid_to_show += last_horizontal_line\n",
    "        grid_to_show+=f\"\\n Possible actions: {self.get_possible_actions()}\"\n",
    "        return grid_to_show\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "┌────┬────┬────┐\n",
      "│  7 │  4 │  5 │\n",
      "├────┼────┼────┤\n",
      "│  2 │    │  3 │\n",
      "├────┼────┼────┤\n",
      "│  8 │  1 │  6 │\n",
      "└────┴────┴────┘\n",
      "\n",
      " Possible actions: [0, 1, 2, 3]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid=Grid(size=3)\n",
    "print(grid)\n",
    "grid.is_finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Game:\n",
    "    def __init__(self) -> None:\n",
    "        self.grid=Grid()\n",
    "        self.end=False\n",
    "        self.round=0\n",
    "        self.reward=0\n",
    "        self.sum_reward=0\n",
    "        self.actions=[]# list of all actions done in the game\n",
    "        self.last_good=0\n",
    "        self.number_good_place=0\n",
    "\n",
    "    def play_round(self):\n",
    "        \"\"\"function_agent : fonction de choix de l'agent\"\"\"\n",
    "        reward=-1\n",
    "        action=random.choice(self.grid.get_possible_actions())\n",
    "        #action=np.random.randint(0,3)\n",
    "        self.grid.take_action(action)\n",
    "        if self.grid.is_finish():\n",
    "          self.end = True\n",
    "          reward += 50\n",
    "        print(f\"Number of well placed : {self.grid.get_good_place()}\")\n",
    "        if self.grid.get_good_place() == self.number_good_place:\n",
    "          reward -= self.last_good # more we dont increase the number of well positioned stuff more reward we loose\n",
    "          self.last_good += 1\n",
    "        elif self.grid.get_good_place() < self.number_good_place:\n",
    "          reward -= 5\n",
    "        else:\n",
    "          reward+=self.grid.get_good_place()\n",
    "          self.number_good_place = self.grid.get_good_place()\n",
    "        return reward,self.grid.state,action\n",
    "\n",
    "\n",
    "    def play_game(self):\n",
    "        while not self.end and self.round < 1000:\n",
    "            reward,state,action=self.play_round()\n",
    "            self.reward=reward\n",
    "            self.sum_reward+=reward\n",
    "            self.actions.append(action)\n",
    "            self.round+=1\n",
    "            print(f\"round: {self.round}\")\n",
    "            print(f\"action: {action}\")\n",
    "            print(f\"Sum of reward: {self.sum_reward}\")\n",
    "            print(self.grid)\n",
    "\n",
    "    def __str__(self):\n",
    "        game_to_show=f\"---- {self.round} ----------\\n\"\n",
    "        game_to_show+=self.grid.__str__()\n",
    "        game_to_show+=f\"\\nReward Round{self.reward} \\nReward cum:{self.sum_reward}\"\n",
    "        return game_to_show\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "gg=Game()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gg.play_game()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Qlearning:\n",
    "    def __init__(self, actions, alpha=0.1, gamma=0.9, epsilon=0.1,size=2):\n",
    "        self.Q = {}\n",
    "        self.actions = actions\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.size=size**2\n",
    "\n",
    "    def get_Q(self, state, action):\n",
    "        if tuple(state.reshape(self.size)) not in self.Q:\n",
    "            self.Q[tuple(state.reshape(self.size))] = np.zeros(len(self.actions))\n",
    "        return self.Q[tuple(state.reshape(self.size))][action]\n",
    "\n",
    "    def choose_action(self, state,possible_actions):\n",
    "        if np.random.uniform() < self.epsilon:\n",
    "            # Choose a random action\n",
    "            return np.random.choice(possible_actions)\n",
    "        else:\n",
    "            # Choose the action with the highest Q-value\n",
    "            q_values = [self.get_Q(state, a) for a in possible_actions]\n",
    "            max_q = max(q_values)\n",
    "            if q_values.count(max_q) > 1:\n",
    "                # Multiple actions have the same highest Q-value, choose one randomly\n",
    "                \n",
    "                return possible_actions[np.random.choice(np.flatnonzero(np.array(q_values) == np.array(q_values).max()))]\n",
    "            else:\n",
    "                return possible_actions[np.argmax(q_values)]\n",
    "\n",
    "    def update(self, state, action, reward, next_state):\n",
    "        old_Q = self.get_Q(state, action)\n",
    "        next_max_Q = max([self.get_Q(next_state, a) for a in self.actions])\n",
    "        new_Q = old_Q + self.alpha * (reward + self.gamma * next_max_Q - old_Q)\n",
    "        #print(action,reward)\n",
    "        self.Q[tuple(state.reshape(self.size))][action] = new_Q\n",
    "        #print(self.Q)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size=3\n",
    "qlearner = Qlearning(actions=[0, 1, 2, 3],size=size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qlearner.epsilon=0.7\n",
    "\n",
    "nb_game = 1000\n",
    "win=0\n",
    "for i in range(nb_game):\n",
    "  game = Game(size=size)\n",
    "  round=0\n",
    "  res=game.play_game(qlearner,25000)\n",
    "  if res:\n",
    "    win+=1\n",
    "  print(i,res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f3d42ad487b2b2994e012ab0306cc0a65d83ea9d079e1ade1e8453053e613de7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
